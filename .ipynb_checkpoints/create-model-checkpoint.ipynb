{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bd0ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "from PIL import Image \n",
    "from PIL.ImageDraw import Draw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb8e931",
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 216\n",
    "height = 216\n",
    "num_classes = 2\n",
    "classes = [\"Circle\", \"No-Circle\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627bfffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_CSV_FILE = 'Data/training_data.csv'\n",
    "VALIDATION_CSV_FILE = 'Data/validation_data.csv'\n",
    "TRAINING_IMAGE_DIR = 'Images/Training'\n",
    "VALIDATION_IMAGE_DIR = 'Images/Validation'\n",
    "\n",
    "training_image_records = pd.read_csv(TRAINING_CSV_FILE)\n",
    "validation_image_records = pd.read_csv(VALIDATION_CSV_FILE)\n",
    "\n",
    "train_image_path = os.path.join(os.getcwd(), TRAINING_IMAGE_DIR)\n",
    "validation_image_path = os.path.join(os.getcwd(), VALIDATION_IMAGE_DIR)\n",
    "\n",
    "train_images = []\n",
    "train_targets = []\n",
    "train_labels = []\n",
    "\n",
    "for index, row in training_image_records.iterrows():\n",
    "    \n",
    "    (filename, width, height, class_name, xmin, ymin, xmax, ymax) = row\n",
    "    \n",
    "    train_image_fullpath = os.path.join(train_image_path, filename)\n",
    "    train_img = keras.preprocessing.image.load_img(train_image_fullpath, target_size=(height, width))\n",
    "    train_img_arr = keras.preprocessing.image.img_to_array(train_img)\n",
    "    \n",
    "    \n",
    "    xmin = round(xmin/ width, 2)\n",
    "    ymin = round(ymin/ height, 2)\n",
    "    xmax = round(xmax/ width, 2)\n",
    "    ymax = round(ymax/ height, 2)\n",
    "    \n",
    "    train_images.append(train_img_arr)\n",
    "    train_targets.append((xmin, ymin, xmax, ymax))\n",
    "    train_labels.append(classes.index(class_name))\n",
    "    \n",
    "    \n",
    "    \n",
    "validation_images = []\n",
    "validation_targets = []\n",
    "validation_labels = []\n",
    "\n",
    "for index, row in validation_image_records.iterrows():\n",
    "    \n",
    "    (filename, width, height, class_name, xmin, ymin, xmax, ymax) = row\n",
    "    \n",
    "    validation_image_fullpath = os.path.join(validation_image_path, filename)\n",
    "    validation_img = keras.preprocessing.image.load_img(validation_image_fullpath, target_size=(height, width))\n",
    "    validation_img_arr = keras.preprocessing.image.img_to_array(validation_img)\n",
    "    #img_arr = img_arr/255.0\n",
    "    \n",
    "    xmin = round(xmin/ width, 2)\n",
    "    ymin = round(ymin/ height, 2)\n",
    "    xmax = round(xmax/ width, 2)\n",
    "    ymax = round(ymax/ height, 2)\n",
    "    \n",
    "    validation_images.append(validation_img_arr)\n",
    "    validation_targets.append((xmin, ymin, xmax, ymax))\n",
    "    validation_labels.append(classes.index(class_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68523f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the common input layer\n",
    "input_shape = (height, width, 3)\n",
    "input_layer = tf.keras.layers.Input(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6f4ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_layers = layers.experimental.preprocessing.Rescaling(1./255, name='bl_1')(input_layer)\n",
    "base_layers = layers.Conv2D(16, 3, padding='same', activation='relu', name='bl_2')(base_layers)\n",
    "base_layers = layers.MaxPooling2D(name='bl_3')(base_layers)\n",
    "base_layers = layers.Conv2D(32, 3, padding='same', activation='relu', name='bl_4')(base_layers)\n",
    "base_layers = layers.MaxPooling2D(name='bl_5')(base_layers)\n",
    "base_layers = layers.Conv2D(64, 3, padding='same', activation='relu', name='bl_6')(base_layers)\n",
    "base_layers = layers.MaxPooling2D(name='bl_7')(base_layers)\n",
    "base_layers = layers.Flatten(name='bl_8')(base_layers)\n",
    "\n",
    "classifier_branch = layers.Dense(128, activation='relu', name='cl_1')(base_layers)\n",
    "classifier_branch = layers.Dense(num_classes, name='cl_head')(classifier_branch)  \n",
    "\n",
    "locator_branch = layers.Dense(128, activation='relu', name='bb_1')(base_layers)\n",
    "locator_branch = layers.Dense(64, activation='relu', name='bb_2')(locator_branch)\n",
    "locator_branch = layers.Dense(32, activation='relu', name='bb_3')(locator_branch)\n",
    "locator_branch = layers.Dense(4, activation='sigmoid', name='bb_head')(locator_branch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4d157f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Model(input_layer, outputs=[classifier_branch, locator_branch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bf13f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a936be9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = {\"cl_head\":tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \"bb_head\":tf.keras.losses.MSE}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edb671b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=losses, optimizer='Adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11a6ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_epochs = 20\n",
    "\n",
    "train_images = np.array(train_images)\n",
    "train_targets = np.array(train_targets)\n",
    "train_labels = np.array(train_labels)\n",
    "\n",
    "validation_images = np.array(validation_images)\n",
    "validation_targets = np.array(validation_targets)\n",
    "validation_labels = np.array(validation_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6cb3057",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainTargets = {\n",
    "    \"cl_head\": train_labels,\n",
    "    \"bb_head\": train_targets\n",
    "}\n",
    "\n",
    "validationTargets = {\n",
    "    \"cl_head\": validation_labels,\n",
    "    \"bb_head\": validation_targets\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cee1e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(trainTargets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ab214e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(train_images, trainTargets,\n",
    "                   validation_data=(validation_images, validationTargets),\n",
    "                   batch_size=4,\n",
    "                   epochs=training_epochs,\n",
    "                   shuffle=True,\n",
    "                   verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda7fc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_accuracy = history.history['cl_head_accuracy']\n",
    "cl_val_acc = history.history['val_cl_head_accuracy']\n",
    "\n",
    "bb_accuracy = history.history['bb_head_accuracy']\n",
    "bb_val_acc = history.history['val_bb_head_accuracy']\n",
    "\n",
    "cl_loss = history.history['cl_head_loss']\n",
    "cl_val_loss = history.history['val_cl_head_loss']\n",
    "\n",
    "bb_loss = history.history['bb_head_loss']\n",
    "bb_val_loss = history.history['val_bb_head_loss']\n",
    "\n",
    "\n",
    "\n",
    "epochs_range = range(training_epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, bb_accuracy, label='Training Accuracy')\n",
    "plt.plot(epochs_range, bb_val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Localisation branch - Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, bb_loss, label='Training Loss')\n",
    "plt.plot(epochs_range, bb_val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Localisation branch - Loss')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, cl_accuracy, label='Training Accuracy')\n",
    "plt.plot(epochs_range, cl_val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Classification branch - Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, cl_loss, label='Training Loss')\n",
    "plt.plot(epochs_range, cl_val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Classification branch - Loss')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb36ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_img = 'Test/20210620_155720.jpg'\n",
    "\n",
    "img = keras.preprocessing.image.load_img(validation_img, target_size=(height, width))\n",
    "\n",
    "img = keras.preprocessing.image.img_to_array(img)\n",
    "img = tf.expand_dims(img, 0)\n",
    "predictions = model.predict(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3502fd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictions[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7ba6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox = predictions[1][0]\n",
    "bbox = [bbox[0] * width, bbox[1] * height, bbox[2] * width, bbox[3] * height]\n",
    "print(bbox)\n",
    "\n",
    "class_prediction_value = predictions[0][0]\n",
    "score = tf.nn.softmax(class_prediction_value)\n",
    "\n",
    "print(score)\n",
    "score = tf.math.argmax(score)\n",
    "print(\"Predicted class: {}\".format(classes[score]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbca2fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "testimg = keras.preprocessing.image.load_img(validation_img, target_size=(height, width))\n",
    "draw1 = Draw(testimg)\n",
    "draw1.rectangle(bbox, outline='red')\n",
    "testimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f853df65",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./Saved-Models/Locator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac5950a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    if layer.name.startswith('bl_'):\n",
    "        print(layer.name)\n",
    "        layer.trainable = False\n",
    "        \n",
    "for layer in model.layers:\n",
    "    if layer.name.startswith('bb_'):\n",
    "        print(layer.name)\n",
    "        layer.trainable = False"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
